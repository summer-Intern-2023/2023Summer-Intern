{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP/1.1 400 Bad Request\n",
      "Date: Wed, 28 Jun 2023 01:25:32 GMT\n",
      "Server: Apache/2.4.18 (Ubuntu)\n",
      "Content-Length: 308\n",
      "Connection: close\n",
      "Content-Type: text/html; charset=iso-8859-1\n",
      "\n",
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>400 Bad Request</title>\n",
      "</head><body>\n",
      "<h1>Bad Request</h1>\n",
      "<p>Your browser sent a request that this server could not understand.<br />\n",
      "</p>\n",
      "<hr>\n",
      "<address>Apache/2.4.18 (Ubuntu) Server at do1.dr-chuck.com Port 80</address>\n",
      "</body></html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Example1\n",
    "import socket\n",
    "\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect(('data.pr4e.org',80))\n",
    "cmd = 'GET http://data.pr4e.org/romeo.txt HTTP.1.0\\n\\n'.encode()\n",
    "mysock.send(cmd)\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(512)\n",
    "    if (len(data) < 1):\n",
    "        break\n",
    "    print(data.decode())\n",
    "mysock.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP/1.1 200 OK\n",
      "Date: Wed, 28 Jun 2023 01:49:48 GMT\n",
      "Server: Apache/2.4.18 (Ubuntu)\n",
      "Last-Modified: Sat, 13 May 2017 11:22:22 GMT\n",
      "ETag: \"1d3-54f6609240717\"\n",
      "Accept-Ranges: bytes\n",
      "Content-Length: 467\n",
      "Cache-Control: max-age=0, no-cache, no-store, must-revalidate\n",
      "Pragma: no-cache\n",
      "Expires: Wed, 11 Jan 1984 05:00:00 GMT\n",
      "Connection: close\n",
      "Content-Type: text/plain\n",
      "\n",
      "Why should you learn to write programs?\n",
      "\n",
      "Writing programs (or programming) is a very creative \n",
      "and rewarding activity.  You can write programs for \n",
      "many reasons, ranging from making your living to solving\n",
      "a difficult data analysis problem to having fun to helping\n",
      "someone else solve a problem.  This book assumes that \n",
      "everyone needs to know how to program, and that once \n",
      "you know how to program you will figure out what you want \n",
      "to do with your newfound skills.  \n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect(('data.pr4e.org', 80))\n",
    "cmd = 'GET http://data.pr4e.org/intro-short.txt HTTP/1.0\\r\\n\\r\\n'.encode()\n",
    "mysock.send(cmd)\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(512)\n",
    "    if len(data) < 1:\n",
    "        break\n",
    "    print(data.decode(),end='')\n",
    "\n",
    "mysock.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "#Example2.1\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "for line in fhand:\n",
    "    print(line.decode().strip())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'But': 1, 'soft': 1, 'what': 1, 'light': 1, 'through': 1, 'yonder': 1, 'window': 1, 'breaks': 1, 'It': 1, 'is': 3, 'the': 3, 'east': 1, 'and': 3, 'Juliet': 1, 'sun': 2, 'Arise': 1, 'fair': 1, 'kill': 1, 'envious': 1, 'moon': 1, 'Who': 1, 'already': 1, 'sick': 1, 'pale': 1, 'with': 1, 'grief': 1}\n"
     ]
    }
   ],
   "source": [
    "#Example2.2\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "\n",
    "counts = dict()\n",
    "for line in fhand:\n",
    "    words = line.decode().split()\n",
    "    for word in words:\n",
    "        counts[word] = counts.get(word,0) + 1\n",
    "        \n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'method' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m url \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEnter-\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m html \u001b[39m=\u001b[39m urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39murlopen(url, context\u001b[39m=\u001b[39mctx)\u001b[39m.\u001b[39mread\n\u001b[1;32m---> 12\u001b[0m soup \u001b[39m=\u001b[39m BeautifulSoup(html,\u001b[39m'\u001b[39;49m\u001b[39mhtml.parser\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     14\u001b[0m tags \u001b[39m=\u001b[39m soup(\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m tag \u001b[39min\u001b[39;00m tags:\n",
      "File \u001b[1;32mc:\\Users\\ZXR\\Desktop\\2023summer\\2023Summer-Intern\\UMICH Py4E\\Xinran Zheng\\bs4\\__init__.py:314\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(markup, \u001b[39m'\u001b[39m\u001b[39mread\u001b[39m\u001b[39m'\u001b[39m):        \u001b[39m# It's a file-type object.\u001b[39;00m\n\u001b[0;32m    313\u001b[0m     markup \u001b[39m=\u001b[39m markup\u001b[39m.\u001b[39mread()\n\u001b[1;32m--> 314\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39;49m(markup) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m256\u001b[39m \u001b[39mand\u001b[39;00m (\n\u001b[0;32m    315\u001b[0m         (\u001b[39misinstance\u001b[39m(markup, \u001b[39mbytes\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m<\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m markup)\n\u001b[0;32m    316\u001b[0m         \u001b[39mor\u001b[39;00m (\u001b[39misinstance\u001b[39m(markup, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m<\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m markup)\n\u001b[0;32m    317\u001b[0m ):\n\u001b[0;32m    318\u001b[0m     \u001b[39m# Issue warnings for a couple beginner problems\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39m# involving passing non-markup to Beautiful Soup.\u001b[39;00m\n\u001b[0;32m    320\u001b[0m     \u001b[39m# Beautiful Soup will still parse the input as markup,\u001b[39;00m\n\u001b[0;32m    321\u001b[0m     \u001b[39m# since that is sometimes the intended behavior.\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_markup_is_url(markup):\n\u001b[0;32m    323\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_markup_resembles_filename(markup)                \n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'method' has no len()"
     ]
    }
   ],
   "source": [
    "#Example3\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url = input(\"Enter-\")\n",
    "html = urllib.request.urlopen(url, context=ctx).read\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "tags = soup('a')\n",
    "for tag in tags:\n",
    "    print(tag.get('href', None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count 50\n",
      "Sum 2554\n"
     ]
    }
   ],
   "source": [
    "# Assignment Scraping HTML\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url = input('Enter - ')\n",
    "html = urlopen(url, context=ctx).read()\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Retrieve all of the anchor tags\n",
    "tags = soup('span')\n",
    "counts, total = 0, 0\n",
    "for tag in tags:\n",
    "   '''\n",
    "    print('TAG:', tag)\n",
    "    print('URL:', tag.get('href', None))\n",
    "    print('Contents:', tag.contents[0])\n",
    "    print('Attrs:', tag.attrs)\n",
    "   '''\n",
    "   if tag.contents[0] is not None:\n",
    "      counts += 1\n",
    "      total = total + int(tag.contents[0])\n",
    "print(\"Count\", counts)\n",
    "print(\"Sum\", total)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving: http://py4e-data.dr-chuck.net/known_by_Jedidiah.html\n",
      "Retrieving: http://py4e-data.dr-chuck.net/known_by_Sharon.html\n",
      "Retrieving: http://py4e-data.dr-chuck.net/known_by_Boudicca.html\n",
      "Retrieving: http://py4e-data.dr-chuck.net/known_by_Aiman.html\n",
      "Retrieving: http://py4e-data.dr-chuck.net/known_by_Hareem.html\n",
      "Retrieving: http://py4e-data.dr-chuck.net/known_by_Alishah.html\n",
      "Retrieving: http://py4e-data.dr-chuck.net/known_by_Sandra.html\n",
      "Retrieving: http://py4e-data.dr-chuck.net/known_by_Emilia.html\n"
     ]
    }
   ],
   "source": [
    "# To run this, download the BeautifulSoup zip file\n",
    "# http://www.py4e.com/code3/bs4.zip\n",
    "# and unzip it in the same directory as this file\n",
    "\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url = input('Enter - ')\n",
    "html = urllib.request.urlopen(url, context=ctx).read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Retrieve all of the anchor tags\n",
    "tags = soup('a')\n",
    "\n",
    "position, processnum, count = 0, 0, 0\n",
    "\n",
    "count = input(\"Enter count:\")\n",
    "position = input(\"Enter position:\")\n",
    "\n",
    "for tag in tags:\n",
    "    processnum += 1\n",
    "    if processnum >= int(position) and processnum <= (int(position) + int(count)):\n",
    "        print(\"Retrieving:\", tag.get('href', None))\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
